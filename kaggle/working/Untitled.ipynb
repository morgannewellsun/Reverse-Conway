{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-364828d17c45>\", line 9, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 85, in <module>\n",
      "    from tensorflow.python.ops.standard_ops import *\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\standard_ops.py\", line 26, in <module>\n",
      "    from tensorflow.python import autograph\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 35, in <module>\n",
      "    from tensorflow.python.autograph import operators\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import ConversionOptions\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 69, in <module>\n",
      "    from tensorflow.python.autograph.pyct import anno\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\anno.py\", line 27, in <module>\n",
      "    import gast\n",
      "ModuleNotFoundError: No module named 'gast'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 44, in <module>\n",
      "    from . _api.v2 import autograph\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\autograph\\__init__.py\", line 22, in <module>\n",
      "    from . import experimental\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\autograph\\experimental\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import Feature\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 69, in <module>\n",
      "    from tensorflow.python.autograph.pyct import anno\n",
      "  File \"C:\\Users\\Morgan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\anno.py\", line 27, in <module>\n",
      "    import gast\n",
      "ModuleNotFoundError: No module named 'gast'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gast'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "from typing import *\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pathlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# USER SETTINGS# USER SETTINGS\n",
    "\n",
    "MODEL_ROOT_DIR = '../input/conway/cnn_models/'\n",
    "CNN_PATHS = {\n",
    "    \"delta_1_final\": MODEL_ROOT_DIR + \"delta_1_final\",\n",
    "    # \"delta_1\": MODEL_ROOT_DIR + \"delta_1\",\n",
    "    # \"delta_2\": MODEL_ROOT_DIR + \"delta_2\",\n",
    "    # \"delta_3\": MODEL_ROOT_DIR + \"delta_3\",\n",
    "    # \"delta_4\": MODEL_ROOT_DIR + \"delta_4\",\n",
    "    # \"delta_5\": MODEL_ROOT_DIR + \"delta_5\",\n",
    "}\n",
    "CNN_MODELS = dict([(name, tf.saved_model.load(path)) for name, path in CNN_PATHS.items()])\n",
    "KAGGLE_TEST_FILE_PATH = '../input/conways-reverse-game-of-life-2020/test.csv'\n",
    "OUTPUT_DIR = './'\n",
    "\n",
    "BATCH_SIZE = 10  # Delta group size\n",
    "RANDOM_SEED = 0  # Used in genetic algorithm ReverseGa\n",
    "\n",
    "GA_STATIC_POP = 10  # GA initial population from the static prob\n",
    "GA_DYNAMIC_POP = 10  # GA initial population from the dynamic prob\n",
    "\n",
    "# ga_static_1 = 10  # GA initial population from the static prob, step-wise\n",
    "# ga_static_n = 10  # GA initial population from the static prob, direct solver\n",
    "# ga_dynamic_1 = 10  # GA initial population from the dynamic prob, step-wise\n",
    "# ga_dynamic_n = 10  # GA initial population from the dynamic prob, direct solver\n",
    "# ga_pop_size = ga_static_1 + ga_static_n + ga_dynamic_1 + ga_dynamic_n\n",
    "# ga_max_iters = 100\n",
    "# ga_cross = 0.7  # GA cross ratio\n",
    "# ga_mutate = 0.7  # GA mutation population ratio\n",
    "# ga_mut_div = 100  # GA cell mutation probability is 1/ga_mut_div\n",
    "# ga_save_states = False  # Should we save CNN state, GA state, and end state?\n",
    "# status_freq = 200  # Report frequency in terms of number of games\n",
    "# track_details = False\n",
    "\n",
    "# The following settings restricts to only a selected subset of data to test.\n",
    "DELTA_SET = {1}  # Load only the model for specified deltas. To load all, use {1,2,3,4,5}\n",
    "GAME_IDX_MIN = 50003  # Kaggle test game indices from 50000 to 99999.\n",
    "GAME_IDX_MAX = 50003  # To test for 1000 rows, use 51000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Conway's game logic\n",
    "\n",
    "class BinaryConwayForwardPropFn:\n",
    "\n",
    "    def __init__(self, numpy_mode=False, nrows=25, ncols=25):\n",
    "        self._numpy_mode = numpy_mode\n",
    "        self.nrows = nrows\n",
    "        self.ncols = ncols\n",
    "        self._moore_offsets = [(i, j) for i in [-1, 0, 1] for j in [-1, 0, 1] if (i != 0 or j != 0)]\n",
    "\n",
    "    def __call__(self, inputs, delta=1):\n",
    "        # inputs is a np array of at least 3D, usually 4D, of shape:\n",
    "        # (popsize, batch_size, game board width, game board height, 1).\n",
    "        # outputs will be of the same shape as inputs.\n",
    "        # For an example of use, see\n",
    "        # Reverse-Conway/src/data/tests/verify_kaggle_training.py\n",
    "        outputs = inputs\n",
    "        for _ in range(delta):\n",
    "            outputs = self._one_delta(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def _one_delta(self, inputs):\n",
    "        if self._numpy_mode:\n",
    "            neighbors = [np.roll(inputs, shift, (-3, -2)) for shift in self._moore_offsets]\n",
    "            live_neighbor_counts = np.count_nonzero(neighbors, axis=0)\n",
    "            two_live_neighbors = np.equal(live_neighbor_counts, 2)\n",
    "            three_live_neighbors = np.equal(live_neighbor_counts, 3)\n",
    "            outputs = np.logical_or(three_live_neighbors, np.logical_and(two_live_neighbors, inputs))\n",
    "        else:\n",
    "            neighbors = [tf.roll(inputs, shift, (-3, -2)) for shift in self._moore_offsets]\n",
    "            live_neighbor_counts = tf.math.count_nonzero(neighbors, axis=0)\n",
    "            two_live_neighbors = tf.math.equal(live_neighbor_counts, 2)\n",
    "            three_live_neighbors = tf.math.equal(live_neighbor_counts, 3)\n",
    "            outputs = tf.math.logical_or(three_live_neighbors, tf.math.logical_and(two_live_neighbors, inputs))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Generate initial reverse same guesses using CNN.\n",
    "\n",
    "class CNN:\n",
    "    # Initializes a GA population using a CNN reverse model.\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            model: tf.function,\n",
    "            population_size_static: int,\n",
    "            population_size_dynamic: int,\n",
    "            static_prob_threshold_span: float):\n",
    "        # Arg cnn_reverters is a dictionary from int (delta)\n",
    "        # to a CNN solver. A solver accepts array of np.float32.\n",
    "        self._model = model\n",
    "        self._population_size_static = population_size_static\n",
    "        self._population_size_dynamic = population_size_dynamic\n",
    "        self._bars_static = tf.reshape(\n",
    "            (\n",
    "                tf.linspace(\n",
    "                    0.5 - static_prob_threshold_span,\n",
    "                    0.5 + static_prob_threshold_span,\n",
    "                    num=self._population_size_static)\n",
    "                if self._population_size_static > 1\n",
    "                else tf.constant(0.5)\n",
    "            ),\n",
    "            shape=(-1, 1, 1, 1, 1))\n",
    "\n",
    "    '''\n",
    "    def _revert_many(self, model, stop_states):\n",
    "        # Use CNN to revert many boards by 50% threshold.\n",
    "        # Arg stop_states is an array of size\n",
    "        # (number of boards, nrows, ncols, number of guesses).\n",
    "        cnn_result = model(stop_states.astype(np.float32)).numpy()\n",
    "        return cnn_result >= 0.5\n",
    "    '''\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(None, 25, 25, 1), dtype=tf.float32)])\n",
    "    def _revert_static(self, stop_state) -> tf.Tensor:\n",
    "        cnn_result = self._model(stop_state)  # (batch, 25, 25, 1)\n",
    "        x = tf.greater_equal(cnn_result, self._bars_static)  # (pop, batch, 25, 25, 1)\n",
    "        return x\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(None, 25, 25, 1), dtype=tf.float32)])\n",
    "    def _revert_dynamic(self, stop_state) -> tf.Tensor:\n",
    "        cnn_result = self._model(stop_state)  # (batch, 25, 25, 1)\n",
    "        noise = tf.random.uniform(\n",
    "            shape=(self._population_size_dynamic, 1, 25, 25, 1),\n",
    "            minval=0, maxval=1,\n",
    "            dtype=tf.dtypes.float32)\n",
    "        x = tf.greater_equal(cnn_result, noise)  # (pop, batch, 25, 25, 1)\n",
    "        return x\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(None, 25, 25, 1), dtype=tf.float32)])\n",
    "    def revert(self, stop_state: tf.Tensor) -> tf.Tensor:\n",
    "        # stop_state: (batch, 25, 25, 1)\n",
    "        # output: (population, batch, 25, 25, 1)\n",
    "        if self._population_size_dynamic == 0 and self._population_size_static == 0:\n",
    "            raise ValueError(\"At least one population size must be nonzero\")\n",
    "        stop_state_expanded = tf.expand_dims(stop_state, axis=0)\n",
    "        all_zeros = tf.zeros_like(stop_state_expanded)\n",
    "        guesses = [stop_state_expanded, all_zeros]\n",
    "        if self._population_size_dynamic != 0:\n",
    "            guesses.append(self._revert_dynamic(stop_state))\n",
    "        if self._population_size_static != 0:\n",
    "            return self._revert_static(stop_state)\n",
    "        return tf.concat(guesses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Enhance revert game results using genetic algorithm.\n",
    "\n",
    "class GA:\n",
    "\n",
    "    def __init__(self, *, iterations: int, delta: int, mutations_per_board: int, random_seed: int):\n",
    "        self._conway = BinaryConwayForwardPropFn()\n",
    "        self._iterations = iterations\n",
    "        self._delta = delta\n",
    "        self._mutations_per_board = tf.constant(mutations_per_board)\n",
    "        self._tf_random_generator = tf.random.Generator.from_seed(random_seed)\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.float32)])\n",
    "    def _generate_mutations(self, population: tf.Tensor, population_diffs: tf.Tensor) -> tf.Tensor:\n",
    "        target_areas = tf.reduce_any(\n",
    "            [tf.roll(population_diffs, (i, j), (-3, -2)) for i in [-1, 0, 1] for j in [-1, 0, 1]],\n",
    "            axis=0)  # (pop, batch, 25, 25, 1)\n",
    "        target_area_sizes = tf.reshape(\n",
    "            tf.math.count_nonzero(target_areas, axis=(0, 1)),\n",
    "            shape=(GA_STATIC_POP + GA_DYNAMIC_POP, -1, 1, 1, 1))  # (pop, batch, 1, 1, 1)\n",
    "        muter_threshold = self._mutations_per_board / (target_area_sizes + 1)  # (pop, batch, 1, 1, 1)\n",
    "        muters = tf.random.uniform(\n",
    "            shape=(GA_STATIC_POP + GA_DYNAMIC_POP, 1, 25, 25, 1),\n",
    "            minval=0, maxval=1,\n",
    "            dtype=tf.dtypes.float32)  # (pop, 1, 25, 25, 1)\n",
    "        muters = tf.greater_equal(muter_threshold, muters)  # (pop, batch, 25, 25, 1)\n",
    "        muters &= target_areas  # (pop, batch, 25, 25, 1)\n",
    "        return tf.math.logical_xor(population, muters)\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.float32)])\n",
    "    def _generate_crossovers(self, population: tf.Tensor) -> tf.Tensor:\n",
    "        shuffled_population = tf.random.shuffle(population)\n",
    "        cell_swapper = tf.greater_equal(\n",
    "            tf.random.uniform(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, 1, 25, 25, 1), minval=0, maxval=1),\n",
    "            0.5)\n",
    "        cell_complement = tf.logical_not(cell_swapper)\n",
    "        return tf.logical_or(\n",
    "            tf.logical_and(population, cell_swapper),\n",
    "            tf.logical_and(shuffled_population, cell_complement))\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(None, 25, 25, 1), dtype=tf.bool),\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.bool)])\n",
    "    def _calculate_diffs_and_counts(self, target: tf.Tensor, population: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        for _ in range(self._delta):\n",
    "            population = self._conway(population)\n",
    "        diffs = tf.math.logical_xor(population, target)  # (pop_m, batch, 25, 25, 1)\n",
    "        diff_counts = tf.transpose(tf.math.count_nonzero(diffs, axis=(-3, -2, -1)))  # (batch, pop_m)\n",
    "        return diffs, diff_counts\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(None, 25, 25, 1), dtype=tf.bool),\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.bool),\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.bool),\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None), dtype=tf.int32)])\n",
    "    def _iterate(\n",
    "            self,\n",
    "            target: tf.Tensor,\n",
    "            population: tf.Tensor,\n",
    "            population_diffs: tf.Tensor,\n",
    "            population_diff_counts: tf.Tensor\n",
    "    ) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "        target = tf.reshape(target, shape=(1, -1, 25, 25, 1))\n",
    "        mutations = self._generate_mutations(population, population_diffs)  # (pop_m, batch, 25, 25, 1)\n",
    "        crossovers = self._generate_crossovers(population)  # (pop_c, batch, 25, 25, 1)\n",
    "        mutation_diffs, mutation_diff_counts = self._calculate_diffs_and_counts(target, mutations)\n",
    "        crossover_diffs, crossover_diff_counts = self._calculate_diffs_and_counts(target, crossovers)\n",
    "        population = tf.concat(\n",
    "            [population, mutations, crossovers], axis=0)  # (pop_pmc, batch, 25, 25, 1)\n",
    "        population_diffs = tf.concat(\n",
    "            [population_diffs, mutation_diffs, crossover_diffs], axis=0)  # (pop_pmc, batch, 25, 25, 1)\n",
    "        population_diff_counts = tf.concat(\n",
    "            [population_diff_counts, mutation_diff_counts, crossover_diff_counts], axis=0)  # (batch, pop_pmc)\n",
    "        population_diff_counts, best_indices = tf.math.top_k(\n",
    "            population_diff_counts, k=(GA_STATIC_POP + GA_DYNAMIC_POP), sorted=False)  # (batch, pop_p)\n",
    "        population = tf.transpose(tf.gather(\n",
    "            params=tf.transpose(population, perm=[1, 0, 2, 3, 4]),  # (batch, pop_p, 25, 25, 1)\n",
    "            indices=best_indices,  # (batch, pop_p)\n",
    "            axis=1,\n",
    "            batch_dims=1), perm=[1, 0, 2, 3, 4])  # (pop_p, batch, 25, 25, 1)\n",
    "        population_diffs = tf.transpose(tf.gather(\n",
    "            params=tf.transpose(population_diffs, perm=[1, 0, 2, 3, 4]),  # (batch, pop_p, 25, 25, 1)\n",
    "            indices=best_indices,  # (batch, pop_p)\n",
    "            axis=1,\n",
    "            batch_dims=1), perm=[1, 0, 2, 3, 4])  # (pop_p, batch, 25, 25, 1)\n",
    "        return population, population_diffs, population_diff_counts\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(None, 25, 25, 1), dtype=tf.bool),\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.bool),\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.bool),\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None), dtype=tf.int32)])\n",
    "    def _iterate_last(\n",
    "            self,\n",
    "            target: tf.Tensor,\n",
    "            population: tf.Tensor,\n",
    "            population_diffs: tf.Tensor,\n",
    "            population_diff_counts: tf.Tensor\n",
    "    ) -> tf.Tensor:\n",
    "        target = tf.reshape(target, shape=(1, -1, 25, 25, 1))\n",
    "        mutations = self._generate_mutations(population, population_diffs)  # (pop_m, batch, 25, 25, 1)\n",
    "        crossovers = self._generate_crossovers(population)  # (pop_c, batch, 25, 25, 1)\n",
    "        mutation_stop_states = mutations\n",
    "        crossover_stop_states = crossovers\n",
    "        for _ in range(self._delta):\n",
    "            mutation_stop_states = self._conway(mutation_stop_states)\n",
    "            crossover_stop_states = self._conway(crossover_stop_states)\n",
    "        mutation_diffs = tf.math.logical_xor(mutation_stop_states, target)  # (pop_m, batch, 25, 25, 1)\n",
    "        crossover_diffs = tf.math.logical_xor(crossover_stop_states, target)  # (pop_c, batch, 25, 25, 1)\n",
    "        mutation_diff_counts = tf.transpose(tf.math.count_nonzero(mutation_diffs, axis=(-3, -2, -1)))  # (batch, pop_m)\n",
    "        crossover_diff_counts = tf.transpose(\n",
    "            tf.math.count_nonzero(crossover_diffs, axis=(-3, -2, -1)))  # (batch, pop_c)\n",
    "        population = tf.concat(\n",
    "            [population, mutations, crossovers], axis=0)  # (pop_pmc, batch, 25, 25, 1)\n",
    "        population_diff_counts = tf.concat(\n",
    "            [population_diff_counts, mutation_diff_counts, crossover_diff_counts], axis=0)  # (batch, pop_pmc)\n",
    "        _, best_indices = tf.math.top_k(\n",
    "            population_diff_counts, k=1, sorted=False)  # (batch, 1)\n",
    "        population = tf.transpose(tf.gather(\n",
    "            params=tf.transpose(population, perm=[1, 0, 2, 3, 4]),  # (batch, 1, 25, 25, 1)\n",
    "            indices=best_indices,  # (batch, 1)\n",
    "            axis=1,\n",
    "            batch_dims=1), perm=[1, 0, 2, 3, 4])  # (1, batch, 25, 25, 1)\n",
    "        population = tf.squeeze(population, axis=0)  # (batch, 25, 25, 1)\n",
    "        return population\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(GA_STATIC_POP + GA_DYNAMIC_POP, None, 25, 25, 1), dtype=tf.float32)])\n",
    "    def refine(self, target, population) -> tf.Tensor:\n",
    "        population_diffs, population_diff_counts = self._calculate_diffs_and_counts(target, population)\n",
    "        for _ in range(self._iterations - 1):\n",
    "            population, population_diffs, population_diff_counts = self._iterate(\n",
    "                target, population, population_diffs, population_diff_counts)\n",
    "        return self._iterate_last(target, population, population_diffs, population_diff_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"LOADED!!!\")\n",
    "    my_cnn = CNN(\n",
    "        model=CNN_MODELS[\"delta_1_final\"],\n",
    "        population_size_static=30,\n",
    "        population_size_dynamic=70,\n",
    "        static_prob_threshold_span=0.1)\n",
    "    data = pd.read_csv(KAGGLE_TEST_FILE_PATH, index_col=0, dtype='int')\n",
    "    for idx, row in data.iterrows():\n",
    "        my_stop_state = np.array(row[1:]).astype(np.float32).reshape((1, 25, 25, 1))\n",
    "        output = my_cnn.revert(my_stop_state)\n",
    "        print(output)\n",
    "        print(output.get_shape())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# %% [code]\n",
    "# Utility functions\n",
    "\n",
    "def mylog(title):\n",
    "    global prev_t\n",
    "    t = time.time()\n",
    "    t_sec = round(t - prev_t)\n",
    "    (t_min, t_sec) = divmod(t_sec, 60)\n",
    "    (t_hour, t_min) = divmod(t_min, 60)\n",
    "    prev_t = t\n",
    "    print('{} {} after {}:{}:{}'.format(datetime.now().isoformat(' '), title, t_hour, t_min, t_sec))\n",
    "\n",
    "\n",
    "def save_results(all_submissions, all_results, start_time, end_time):\n",
    "    if len(all_results) == 0:\n",
    "        print('No results were generated.')\n",
    "        return\n",
    "\n",
    "    # Submission file following Kaggle's format\n",
    "    cols = ['id']\n",
    "    cols.extend(['start_' + str(j) for j in range(625)])\n",
    "    pd.DataFrame(all_submissions, columns=cols).to_csv(OUTPUT_DIR + 'submission.csv', index=False)\n",
    "\n",
    "    with pd.ExcelWriter(OUTPUT_DIR + 'run_stats.xlsx', engine='xlsxwriter') as writer:\n",
    "        # Record basic settings for later review with results.\n",
    "        pd.DataFrame([\n",
    "            ['batch_size', BATCH_SIZE],\n",
    "            ['cnn_paths', CNN_PATHS],\n",
    "            ['deltaset', DELTA_SET],\n",
    "            ['ga_cross', ga_cross],\n",
    "            ['ga_mut_div', ga_mut_div],\n",
    "            ['ga_max_iters', ga_max_iters],\n",
    "            ['ga_mutate', ga_mutate],\n",
    "            ['ga_dynamic_1', ga_dynamic_n],\n",
    "            ['ga_dynamic_n', ga_dynamic_n],\n",
    "            ['ga_static_1', ga_static_1],\n",
    "            ['ga_static_n', ga_static_n],\n",
    "            ['ga_pop_size', ga_pop_size],\n",
    "            ['ga_save_states', ga_save_states],\n",
    "            ['game_idx_min', GAME_IDX_MIN],\n",
    "            ['game_idx_max', GAME_IDX_MAX],\n",
    "            ['rand_seed', RANDOM_SEED],\n",
    "            ['stepwise', stepwise],\n",
    "            ['track_details', track_details],\n",
    "            ['start_time', start_time],\n",
    "            ['end_time', end_time]\n",
    "        ], columns=('key', 'value')\n",
    "        ).to_excel(writer, sheet_name='config')\n",
    "        data = pd.DataFrame(all_results, columns=result_header)\n",
    "        data.to_excel(writer, sheet_name='result')\n",
    "\n",
    "        # Generate more statistical reports based on the above data.\n",
    "        game_size = 25 * 25\n",
    "        # statistics by errors\n",
    "        err_col = ['delta ' + str(j) for j in range(6)]\n",
    "        err_stats = pd.DataFrame([[0] * 6] * game_size, columns=err_col)\n",
    "        # statistics by number of lives at the end state\n",
    "        liv_stats = pd.DataFrame([[0] * 3] * game_size, columns=(\n",
    "            'count', 'cnn_fails', 'ga_fails'))\n",
    "        del_stats = pd.DataFrame([[0] * 5] * 6, columns=(\n",
    "            'count', 'cnn_hits', 'ga_hits', 'cnn_fails', 'ga_fails'))\n",
    "\n",
    "        for j, row in data.iterrows():\n",
    "            (game_index, delta, target_lives, cnn_lives, cnn_errors,\n",
    "             ga_lives, ga_errors) = map(int, row[:7])\n",
    "\n",
    "            err_stats.iloc[ga_errors, delta] += 1\n",
    "            liv_stats.iloc[target_lives, 0] += 1\n",
    "            liv_stats.iloc[target_lives, 1] += cnn_errors\n",
    "            liv_stats.iloc[target_lives, 2] += ga_errors\n",
    "            del_stats.iloc[delta, 0] += 1\n",
    "            del_stats.iloc[delta, 3] += cnn_errors\n",
    "            del_stats.iloc[delta, 4] += ga_errors\n",
    "            if cnn_errors == 0:\n",
    "                del_stats.iloc[delta, 1] += 1\n",
    "            if ga_errors == 0:\n",
    "                del_stats.iloc[delta, 2] += 1\n",
    "\n",
    "        err_stats['total'] = err_stats.sum(axis=1)\n",
    "        err_stats = err_stats.loc[err_stats['total'] > 0, :]\n",
    "        err_stats.to_excel(writer, sheet_name='errors')\n",
    "\n",
    "        liv_stats = liv_stats.loc[liv_stats['count'] > 0, :]\n",
    "        liv_stats['cnn_accuracy'] = 1 - liv_stats['cnn_fails'] / liv_stats['count'] / game_size\n",
    "        liv_stats['ga_accuracy'] = 1 - liv_stats['ga_fails'] / liv_stats['count'] / game_size\n",
    "        liv_stats.to_excel(writer, sheet_name='lives')\n",
    "\n",
    "        del_stats = del_stats[del_stats.index > 0]\n",
    "        del_stats['cnn_accuracy'] = 1 - del_stats['cnn_fails'] / del_stats['count'] / game_size\n",
    "        del_stats['ga_accuracy'] = 1 - del_stats['ga_fails'] / del_stats['count'] / game_size\n",
    "        del_stats.to_excel(writer, sheet_name='deltas')\n",
    "\n",
    "        pd.DataFrame(mytime, index=['vallue']).T.to_excel(writer, sheet_name='timing')\n",
    "\n",
    "\n",
    "def tic(key):\n",
    "    myprev[key] = time.time()\n",
    "\n",
    "\n",
    "def toc(key):\n",
    "    mytime[key] += time.time() - myprev[key]\n",
    "\n",
    "# %% [code]\n",
    "# Load CNN models, test file, and set up GA.# Load CNN models, test file, and set up GA.\n",
    "\n",
    "myprev = {'cnn_static': 0, 'cnn_dynamic': 0, 'cnn_total': 0, 'cnn_many': 0, 'ga_total': 0}\n",
    "mytime = myprev.copy()\n",
    "\n",
    "result_header = [\n",
    "    'Game Index', 'Delta', 'Target Lives', 'CNN Lives', 'CNN Errors',\n",
    "    'GA Lives', 'GA Errors']\n",
    "if ga_save_states:\n",
    "    result_header.extend(['Target State', 'CNN Start', 'GA Start'])\n",
    "\n",
    "prev_t = time.time()\n",
    "mylog('Reverse Conway started.')\n",
    "start_time = datetime.now().isoformat(' ')\n",
    "\n",
    "#### Load CNN solvers from files.\n",
    "cnn_manager = CnnMan(cnn_solver, stepwise)\n",
    "mylog('CNN models loaded')\n",
    "\n",
    "\n",
    "#### Load Kaggle test files\n",
    "data = pd.read_csv(KAGGLE_TEST_FILE_PATH, index_col=0, dtype='int')\n",
    "mylog('Kaggle file loaded')\n",
    "\n",
    "#### Apply GA to improve.\n",
    "np.random.seed(RANDOM_SEED)\n",
    "conway = BinaryConwayForwardPropFn(numpy_mode=True, nrows=25, ncols=25)\n",
    "ga = ReverseGa(conway, pop_size=ga_pop_size, max_iters=ga_max_iters,\n",
    "               crossover_rate=ga_cross, mutation_rate=ga_mutate,\n",
    "               mut_div=ga_mut_div,\n",
    "               tracking=track_details, save_states=ga_save_states)\n",
    "\n",
    "# %% [code]\n",
    "# Actual run\n",
    "\n",
    "mylog('GA run started')\n",
    "\n",
    "all_results = []\n",
    "all_submissions = []\n",
    "pathlib.Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "delta_groups = {1: [], 2: [], 3: [], 4: [], 5: []}\n",
    "for idx, row in data.iterrows():\n",
    "    if idx < GAME_IDX_MIN:\n",
    "        continue\n",
    "    if idx > GAME_IDX_MAX:\n",
    "        break\n",
    "    delta = row[0]\n",
    "    if delta not in DELTA_SET:\n",
    "        continue\n",
    "    tf_arr = np.array(row[1:]).astype(np.float32).reshape((25, 25, 1))\n",
    "    delta_groups[delta].append(tf_arr)\n",
    "\n",
    "for delta in [1, 2, 3, 4, 5]:\n",
    "    np_problems = np.stack(delta_groups[delta])  # (n, 25, 25, 1)\n",
    "    batches = np.array_split(np_problems, len(delta_groups[delta]) // BATCH_SIZE, axis=0)  # [(b, 25, 25, 1)]\n",
    "    solved_batches = []\n",
    "    for np_batch in batches:\n",
    "        solved_batches.append(cnn_manager.revert(\n",
    "            np_batch, delta, ga_static_1, ga_static_n, ga_dynamic_1, ga_dynamic_n))\n",
    "\n",
    "\"stop_state, delta, static_1, static_n, dynamic_1, dynamic_n)\"\n",
    "\n",
    "    if len(delta_groups[delta-1]) < batch_size:\n",
    "        continue\n",
    "\n",
    "    np.array(delta_groups[delta-1]).reshape(1, batch_size, 25, 25, 1)\n",
    "    tic('cnn_total')\n",
    "    solv_1 = cnn_manager.revert(delta_groups[delta-1], delta, \n",
    "                                ga_static_1, ga_static_n, ga_dynamic_1, ga_dynamic_n)\n",
    "#         toc('cnn_total')\n",
    "#         tic('ga_total')\n",
    "#         submission, res = ga.revert(idx, delta, delta_groups[delta-1].astype(bool), solv_1)\n",
    "#         toc('ga_total')\n",
    "#         all_submissions.append(submission)\n",
    "#         all_results.append(res)\n",
    "#         delta_groups[delta-1] = None\n",
    "#         if track_details:\n",
    "#             res_dict = dict(zip(result_header[:7], res[:7]))\n",
    "#             detail_file.write('Details for {}:\\n{}\\n\\n'.format(\n",
    "#                 res_dict, ga.summary()))\n",
    "#         if idx % status_freq == 0:\n",
    "#             mylog('Completed game {}.'.format(idx))\n",
    "\n",
    "# save_results(all_submissions, all_results, start_time, datetime.now().isoformat(' '))\n",
    "mylog('Conway solver completed.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
